---
title: "ì›”ë§ˆíŠ¸ ëŒ€íšŒ with Tidymodels"
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 5
    fig_height: 4
    theme: cosmo
    highlight: tango
    code_folding: show
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = "center")
```

Random Forest íŠœë‹ì— ëŒ€í•˜ì—¬ ì•Œì•„ë³´ì.

![Photo steal from [here](https://connectedremag.com/das-in-building-wireless/walmart-verizon-explore-testing-5g-in-some-stores/)](https://connectedremag.com/wp-content/uploads/2020/03/walmart-5G-connected-real-estate.png)

ë³¸ í¬ìŠ¤íŒ…ì€ [ìŠ¬ê¸°ë¡œìš´ í†µê³„ìƒí™œ ìºê¸€ R ìŠ¤í„°ë””](https://www.youtube.com/playlist?list=PLKtLBdGREmMlJCXjCpCi5B4KQ-TsFvAAi) ë°œí‘œìš© í¬ìŠ¤íŒ…ì…ë‹ˆë‹¤.

# ì¤€ë¹„ì‘ì—… {.tabset .tabset-fade}

## Library load

ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œ ì‚¬ìš©í•  RíŒ¨í‚¤ì§€ë“¤ì„ ë¶ˆëŸ¬ì˜¤ì. íŠ¹íˆ ìš”ì¦˜ í•«í•˜ë”” í•«í•œ `tidymodels` ì‚¬ìš©í•˜ì—¬ ì›”ë§ˆíŠ¸ ëŒ€íšŒë¥¼ ê°€ì§€ê³  ë†€ì•„ë³¸ë‹¤. ë˜í•œ ë§ˆì´ ë¹¼ì´ë³´ë¦¿ ì—°ì‚°ìë“¤ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•˜ì—¬ `magrittr`ë¥¼ ë¶ˆëŸ¬ì™”ë‹¤.ğŸ¤£

```{r load_lib, message=FALSE, warning=FALSE, results='hide'}
library(tidymodels)
library(tidyverse)
library(magrittr)
library(skimr)
library(knitr)
theme_set(theme_bw())
```

## Dataset load

ì´ ëŒ€íšŒì—ì„œ ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ë³´ì. ì£¼ì–´ì§„ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

```{r}
file_path <- "../input/walmart-recruiting-store-sales-forecasting/"
files <- list.files(file_path)
files
```
ê° ë³€ìˆ˜ì˜ ì´ë¦„ì„ `janitor` íŒ¨í‚¤ì§€ë¡œ ë§ë”í•˜ê²Œ ë°”ê¿”ì¤€ë‹¤.

```{r, message=FALSE}
train <- read_csv(file.path(file_path, "train.csv.zip")) %>% 
  janitor::clean_names()
test <- read_csv(file.path(file_path, "test.csv.zip")) %>% 
  janitor::clean_names()
features <- read_csv(file.path(file_path, "features.csv.zip")) %>% 
  janitor::clean_names()
stores <- read_csv(file.path(file_path, "stores.csv")) %>% 
  janitor::clean_names()
```

# ë°ì´í„° ê¸°ë³¸ì •ë³´ í™•ì¸{.tabset .tabset-fade}

## Basic info.

ì´ ëŒ€íšŒëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê°„ë‹¨í•œ ëŒ€íšŒì´ë‹¤. ì²«ë²ˆì§¸ ìŠ¤í„°ë””ìš© ëŒ€íšŒë¡œ ì„ íƒì„ í•œ ì´ìœ ì´ê¸°ë„ í•˜ë‹¤. ì£¼ ë°ì´í„°ëŠ” 42ë§Œê°œì˜ train ìƒ˜í”Œê³¼ 11ë§Œê°œì˜ test ìƒ˜í”Œë¡œ êµ¬ì„±ì´ ë˜ì–´ìˆë‹¤.

```{r}
dim(train)
dim(test)
```

ë³€ìˆ˜ëª…ì„ ì‚´í´ë³´ë©´, ì›”ë§ˆíŠ¸ ê°€ë§¹ì ì„ ëœ»í•˜ëŠ” `store` ë³€ìˆ˜ì™€ ë§¤ì¥ì•ˆì˜ ë¶€ì„œë“¤ì„ ë‚˜íƒ€ë‚´ëŠ” `dept`, ë‚ ì§œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆëŠ” `date`ì™€ `is_holiday`, ë§ˆì§€ë§‰ìœ¼ë¡œ ìš°ë¦¬ì˜ target ë³€ìˆ˜ì¸ `weekly_sales`ê°€ ìˆëŠ” ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.

```{r}
names(train)
names(test)
```

## train data

```{r}
skim(train)
```

## test data

```{r}
skim(test)
```

## store data

`store` ë°ì´í„°ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ê°„ë‹¨í•˜ë‹¤. ê° ì í¬ì— ëŒ€í•œ ì‚¬ì´ì¦ˆì™€ íƒ€ì…ë³€ìˆ˜ê°€ ë‹´ê²¨ì ¸ ìˆë‹¤. íƒ€ì…ë³€ìˆ˜ëŠ” ì›”ë§ˆíŠ¸ì—ì„œ ìš´ì˜í•˜ëŠ” supercenterì™€ ê°™ì´ ë§¤ì¥ì˜ ì„±ê²©ì„ ë‚˜íƒ€ë‚´ëŠ” ë³€ìˆ˜ì´ë‹¤.

```{r}
dim(stores)
head(stores)
```


```{r}
skim(stores)
```

## feature data

`feature` ë°ì´í„°ëŠ” ì¡°ê¸ˆ ë³µì¡í•œë°, ê° ì í¬ë³„ë¡œ ê° ì£¼ë§ˆë‹¤ì˜ ì •ë³´ê°€ ë‹´ê²¨ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

```{r}
dim(features)
length(unique(features$Store)) * length(unique(features$Date))

head(features)
```

ì¼ë‹¨ `NA`ì˜ ì¡´ì¬ê°€ ë§ìŒ. `skim()` í•¨ìˆ˜ì˜ complete ì •ë³´ë¥¼ í†µí•˜ì—¬ ì•Œì•„ ë³¼ ìˆ˜ ìˆë‹¤. ë˜í•œ, ëŒ€íšŒ ë°ì´í„°ì— ëŒ€í•œ ì„¤ëª…ì„ ë³´ë©´ `mark_down1-5` ë³€ìˆ˜ì˜ ê²½ìš° ì›”ë§ˆíŠ¸ì—ì„œ ì§„í–‰í•˜ê³  ìˆëŠ” Promotionì„ ì˜ë¯¸í•œë‹¤. í•˜ì§€ë§Œ ì´ ë³€ìˆ˜ì˜ ê²½ìš° 2011ë…„ 11ì›” ì´í›„ì— ë‚ ì§œì— ëŒ€í•˜ì—¬ë§Œ ì ‘ê·¼ ê°€ëŠ¥í•˜ê³ , ê·¸ ì´ì „ì˜ ê²½ìš°ì—ëŠ” `NA`ë¡œ ì±„ì›Œì ¸ìˆë‹¤. ì´ëŸ¬í•œ `NA`ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•  ê²ƒì¸ê°€ê°€ ì´ ëŒ€íšŒì˜ í•µì‹¬ì¼ ê²ƒ ê°™ë‹¤.

```{r}
skim(features)
```


# íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” {.tabset .tabset-fade}

## `weekly_sales`

ë¨¼ì € ìš°ë¦¬ì˜ ì˜ˆì¸¡ ëª©í‘œì¸ ì£¼ê°„ ì„¸ì¼ë³€ìˆ˜ `weekly_sales`ë¥¼ ì‹œê°í™” í•´ë³´ë„ë¡ í•˜ì.

```{r message=FALSE, class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = weekly_sales)) +
  geom_histogram()
```
ë§¤ì¶œì•¡ì˜ ë¶„í¬ë¼ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì—„ì²­ ì¹˜ìš°ì³ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ëŸ° ê²½ìš° ë³´í†µ `log` í•¨ìˆ˜ë¥¼ ì·¨í•´ì¤˜ì„œ ë¶„í¬ì˜ ì¹˜ìš°ì¹¨ì„ ì¡ì•„ì¤€ë‹¤. ì´ë ‡ê²Œ ë¶„í¬ ì¹˜ìš°ì¹¨ì„ ì¡ì•„ì£¼ëŠ” ì´ìœ ëŠ” íšŒê·€ë¶„ì„ ê°™ì€ ì „í†µì ì¸ ê¸°ë²•ì˜ ê²½ìš° ë°ì´í„°ì— ì„ì—¬ìˆëŠ” ì¡ìŒì˜ ë¶„í¬ë¥¼ ì •ê·œë¶„í¬ê°™ì´ ëŒ€ì¹­ì¸ ë¶„í¬ë¡œ ê°€ì •í•˜ëŠ” ê²½ìš°ê°€ ë§ê¸° ë•Œë¬¸ì´ë‹¤. 

```{r message=FALSE, class.source = 'fold-hide'}
train %>% 
    ggplot(aes(x = sign(weekly_sales) * log(abs(weekly_sales) + 2))) +
    geom_histogram() +
    labs(title = "Transformed distribution of weekly sales 1",
         x = "weekly_sales")
```

`log`ë¥¼ ì·¨í•´ì£¼ì—ˆì„ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì´ ì¹˜ìš°ì¹¨ì´ ë§ì´ ì¡íˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ìœ„ì˜ ë¶„í¬ ì—­ì‹œ ì™¼ìª½ìœ¼ë¡œ ì¹˜ìš°ì³ ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë¶„í¬ë¥¼ ì¡°ê¸ˆ ë” ì¢…ëª¨ì–‘ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ê¸° ìœ„í•˜ì—¬ ì œê³±ê·¼ì„ ì´ìš©í–ˆë‹¤. ì•„ë˜ë¥¼ ë³´ë©´ ë¶„í¬ê°€ ì¢…ëª¨ì–‘ì²˜ëŸ¼ ì˜ˆë»ì§„ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

```{r message=FALSE, class.source = 'fold-hide'}
train %>% 
    ggplot(aes(x = sign(weekly_sales) * (abs(weekly_sales))^(1/5))) +
    geom_histogram() +
    labs(title = "Transformed distribution of weekly sales 2",
         x = "weekly_sales")
```

## NA analysis

Rì—ëŠ” ê²°ì¸¡ì¹˜ ë¶„ì„ì„ ì•„ì£¼ ìš©ì´í•˜ê²Œ í•´ì£¼ëŠ” íŒ¨í‚¤ì§€ê°€ í•˜ë‚˜ ì¡´ì¬í•˜ëŠ”ë°, ë°”ë¡œ `naniar`ë¼ëŠ” íŒ¨í‚¤ì§€ ì´ë‹¤.

```{r message=FALSE, warning=FALSE, class.source = 'fold-hide'}
library(naniar)
features %>% 
  select_if(~sum(is.na(.)) > 0) %>% # ê²°ì¸¡ì¹˜ ìˆëŠ” ì¹¼ëŸ¼ ì„ íƒ
  gg_miss_var()
```
`gg_miss_var()`ë¥¼ í†µí•˜ì—¬ í˜„ì¬ mark_down1-5 ë³€ìˆ˜, ê·¸ë¦¬ê³ , unemplomentì™€ cpiê°€ ê²°ì¸¡ì¹˜ê°€ ì¡´ì¬í•˜ëŠ” ê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤.

```{r message=FALSE, class.source = 'fold-hide'}
features %>% 
  select_if(~sum(is.na(.)) > 0) %>%
  gg_miss_upset()
```

`gg_miss_upset()` í•¨ìˆ˜ì˜ ê²½ìš° ê²°ì¸¡ì¹˜ê°€ ë™ì‹œì— ë°œìƒí•˜ëŠ” ë³€ìˆ˜ë“¤ì„ ë³´ì—¬ì£¼ëŠ”ë°, mark_down1-5ê¹Œì§€ê°€ ë™ì‹œì— ì—†ëŠ” ê²°ì¸¡ì¹˜ì˜ ê²½ìš° (ì²«ë²ˆì§¸ ê¸°ë‘¥) 2011ë…„ 11ì›” ì´ì „ì˜ ìë£Œë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

# ì „ì²˜ë¦¬ ë ˆì‹œí”¼(`recipe`) ë§Œë“¤ê¸°

tidymodelsì˜ ì „ì²˜ë¦¬ íŒ¨í‚¤ì§€ì§€ recipeì„ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬ë¥¼ í•˜ë„ë¡í•˜ì.

## `all_data` í•©ì¹˜ê¸°

ë¨¼ì € `store` ì™€ `features` ë°ì´í„°ì— ìˆëŠ” ì •ë³´ë¥¼ `train`ê³¼ `test` ë°ì´í„°ì— ì˜®ê²¨ì˜¤ì. ì¼ë‹¨ ê²°ì¸¡ì¹˜ê°€ ì—†ëŠ” ë³€ìˆ˜ë“¤ë§Œ ê°€ì ¸ì˜¤ê³ , ì¶”í›„ì— ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ë³€ìˆ˜ì¸ cpiì™€ unemployment, mark_down ë³€ìˆ˜ë“¤ì„ ê°€ì ¸ì˜¤ì.

```{r}
all_data <- bind_rows(train, test)
all_data <- left_join(all_data, stores, by = c("store"= "store"))
all_data <- features %>% 
    select(-c(starts_with("mark"), is_holiday)) %>% 
    left_join(all_data, y = ., by = c("store"= "store",
                                      "date" = "date"))

names(all_data)
dim(all_data)
```

## `NA` cpiì™€ unemployment ë³€ìˆ˜

`unemployment`ê³¼ `cpi`ì˜ `NA` ê°’ë“¤ì˜ ê²½ìš°, ê²°ì¸¡ì¹˜ ê°’ì´ 2013ë…„ 5, 6, 7ì›”ì— ì§‘ì¤‘ ë˜ì–´ ìˆëŠ” ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.

```{r}
all_data %>% 
    mutate(year = lubridate::year(date)) %>% 
    mutate(month = lubridate::month(date)) %>% 
    group_by(year, month) %>% 
    summarise(count_na_cpi = sum(is.na(cpi)),
              count_na_unemp = sum(is.na(unemployment))) %>% 
    filter(count_na_cpi > 0 | count_na_unemp > 0)
```

## `cpi`ì™€ `unemployment` ë³€ìˆ˜ `NA` ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°

`cpi`ì™€ `unemployment`ë¥¼ ì¢…ì†ë³€ìˆ˜ë¡œ ì„¤ì • í›„ ë…„ë„, ì›”, ì í¬, ë¶€ì„œ ë³€ìˆ˜ë¥¼ ì´ìš©í•´ì„œ íšŒê·€ë¶„ì„ì„ ì´ìš©í•˜ì—¬ ì±„ìš°ë„ë¡ í•œë‹¤.

```{r}
impute_var <- function(var, all_data, var_name){
  var_train <- all_data %>% 
    select({{var}}, date, store, dept) %>% 
    filter(!is.na({{var}}))
  var_test <- all_data %>% 
    select({{var}}, date, store, dept) %>% 
    filter(is.na({{var}}))
  
  var_rec <- recipe(as.formula(paste0(var_name, "~ .")), var_train) %>% 
      step_mutate(store = as_factor(store),
                  dept = as_factor(dept),
                  year = lubridate::year(date),
                  month = lubridate::month(date)) %>%
      step_dummy(store, dept) %>% 
      prep(training = var_train)
  var_train2 <- juice(var_rec)
  var_test2 <- bake(var_rec, var_test)
  
  lm_model <- 
      linear_reg() %>%
      set_engine("lm")
  
  lm_fit <- 
      lm_model %>% 
      fit(as.formula(paste0(var_name, "~ .")), data = var_train2)
  
  var_impute <- predict(lm_fit, var_test2)
  var_impute$.pred
}
result_cpi <- impute_var(cpi, all_data, "cpi")
result_ump <- impute_var(unemployment, all_data, "unemployment")
all_data$cpi[is.na(all_data$cpi)] <- result_cpi
all_data$unemployment[is.na(all_data$unemployment)] <- result_ump
all_data %>% tail %>% kable()
```

```{r}
all_data %>% 
    summarise_all(~sum(is.na(.)))
```

## `NA` ì™€ markdown 1-5 ë³€ìˆ˜

```{r}
mean_markdown <- features %>%
    filter(date >= "2012-01-01" & date < "2013-01-01") %>% 
    mutate(month = lubridate::month(date)) %>% 
    group_by(store, month) %>% 
    summarise(across(mark_down1:mark_down5, mean, na.rm = T))

mean_markdown %>% 
    summarise_all(~sum(is.na(.))) %>% 
    colSums()

markdown_features <- features %>% 
    mutate(month = lubridate::month(date)) %>% 
    left_join(y = mean_markdown, by = c("store"= "store",
                                              "month" = "month")) %>% 
    mutate(mark_down1 = if_else(is.na(mark_down1.x), mark_down1.y, mark_down1.x),
           mark_down2 = if_else(is.na(mark_down1.x), mark_down2.y, mark_down2.x),
           mark_down3 = if_else(is.na(mark_down1.x), mark_down3.y, mark_down3.x),
           mark_down4 = if_else(is.na(mark_down1.x), mark_down4.y, mark_down4.x),
           mark_down5 = if_else(is.na(mark_down1.x), mark_down5.y, mark_down5.x)) %>% 
    select(store, date, mark_down1:mark_down5)

all_data <- markdown_features %>% 
    left_join(all_data, y = ., by = c("store"= "store",
                                      "date" = "date"))

options(max.print = 20)
names(all_data)
```

## ê³µíœ´ì¼ ë°ì´í„° ì½”ë”©

ë¯¸êµ­ì˜ íœ´ì¼ ì •ë³´ë¥¼ ê°€ì§€ê³ ìˆëŠ” `step_holiday` í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ ë¯¸êµ­ ê³µíœ´ì¼ì„ ëª¨ë‘ ë¹¼ì˜¤ë„ë¡ í•œë‹¤. ë‹¤ìŒì€ ë¯¸êµ­ ê³µíœ´ì¼ ëª©ë¡ì´ë‹¤.

```{r}
timeDate::listHolidays("US")
```

```{r}
library(lubridate)

datedb <- data.frame(date = ymd("2010-1-1") + days(0:(365*4))) %>% 
    filter(date > "2010-01-29" & date < "2013-07-27") %>% 
    mutate(index = 0:(length(date)-1))
datedb$date %>% range()
all_data$date %>% range()

holiday_rec <- recipe(~ date + index, datedb) %>% 
    step_holiday(date,
                 holidays = timeDate::listHolidays("US")) %>% 
    step_mutate(index_mod = index %/% 7) %>% 
    prep(training = datedb) %>% 
    juice()

holiday_rec %<>%
    select(-date) %>% 
    select(starts_with("date"), index_mod) %>% 
    group_by(index_mod) %>% 
    summarise_all(sum) %>% 
    mutate(date = all_data$date %>% unique()) %>% 
    select(date, dplyr::everything())

all_data <- holiday_rec %>% 
    select(-index_mod) %>% 
    left_join(all_data, y = ., by = c("date" = "date"))
all_data %>% head() %>%
  kable()
  
# custom weights
# weight <- c(1, 5)[as_factor(all_data$is_holiday)]
```

## ì „ì²˜ë¦¬ ê³¼ì • ê¸°ë¡í•˜ê¸°

tidymodelì˜ í¸ë¦¬í•œ ì¥ì  ì¤‘ í•˜ë‚˜ëŠ” ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì œê³µí•´ì„œ ì‹¤ì œë¡œ ì „ì²˜ë¦¬ ì½”ë”©ì„ í•˜ì§€ ì•Šì•„ë„ ë˜ë„ë¡ ìë™í™” ì‹œì¼œë†“ì€ ê²ƒì´ë‹¤. ì „ì²˜ë¦¬ë¥¼ í•˜ê³ ì í•˜ëŠ” ë°©ë²•ì„ recipeì— ì ì–´ì£¼ë©´, ë‚˜ì¤‘ì— í•œë²ˆì— ì „ì²˜ë¦¬ë¥¼ ì‹œì¼œì¤€ë‹¤.

ë‹¤ìŒì˜ recipeì—ëŠ” `date` ë³€ìˆ˜ì—ì„œ ë‚ ì§œ ì •ë³´ë¥¼ ë¹¼ì˜¤ê³ , `temperature, fuel_price, cpi, unemployment` ë³€ìˆ˜ë“¤ì„ 10ì°¨í•­ê¹Œì§€ ì½”ë”©í•´ì„œ ë„£ì–´ì£¼ëŠ” ì „ì²˜ë¦¬ ê³¼ì •ì´ ë“¤ì–´ìˆë‹¤.

```{r}
walmart_recipe <- all_data %>% 
    recipe(weekly_sales ~ .) %>%
    step_date(date) %>%
    step_rm(date, date_dow) %>%
    step_poly(temperature, fuel_price, cpi, unemployment,
              degree = 10) %>%
    step_medianimpute(mark_down1, mark_down2, 
                      mark_down3, mark_down4, mark_down5) %>% 
    prep(training = all_data)

print(walmart_recipe)
```

## ì „ì²˜ë¦¬ ë°ì´í„° ì§œë‚´ê¸° (`juice`)

ì €ì¥ëœ `recipe`ì˜ ì „ì²˜ë¦¬ë¥¼ í•œ ë°ì´í„°ë¥¼ `juice` í•¨ìˆ˜ë¡œ ì§œë‚´ë³´ì.

```{r}
all_data2 <- juice(walmart_recipe)
all_data2 %>% dim()
all_data2 %>% head() %>% 
  kable()
```

# ëª¨ë¸ í•™ìŠµí•˜ê¸°

## ë°ì´í„° ë‚˜ëˆ„ê¸°

```{r}
train_index <- seq_len(nrow(train))
train2 <- all_data2[train_index,]
test2 <- all_data2[-train_index,]

train2_isholiday <- train2 %>% filter(is_holiday == TRUE)

# íŠœë‹ì„ ìœ„í•œ validation ë°ì´í„° ì„¤ì •
set.seed(2021)

validation_split <- vfold_cv(train2_isholiday, v = 5)
# validation_split <- validation_split(train2_isholiday, strata = weekly_sales)
```

## íŠœë‹ ìŠ¤í™ ì„¤ì •í•˜ê¸°

```{r}
tune_spec <- rand_forest(mtry = tune(),
                         min_n = tune(),
                         trees = 1000) %>% 
    set_engine("ranger") %>% 
    set_mode("regression")

param_grid <- grid_random(finalize(mtry(), x = train2[,-1]),
                          min_n(),
                          size = 10)
```

## ì›Œí¬í”Œë¡œìš° `workflow()` ì„¤ì •

```{r}
workflow <- workflow() %>%
  add_model(tune_spec) %>% 
  add_formula(weekly_sales ~ .)
```

## Randomforest íŠœë‹í•˜ê¸°

```{r tunerf}
library(doParallel)
Cluster <- makeCluster(detectCores() - 1)
registerDoParallel(Cluster)

library(tictoc)
tic()
tune_result <- workflow %>% 
  tune_grid(validation_split,
            grid = param_grid,
            metrics = metric_set(mae))
toc()
```

```{r}
tune_result$.notes
tune_result %>% 
  collect_metrics()
```

## íŠœë‹ ê²°ê³¼ ì‹œê°í™”

```{r message=FALSE}
tune_result %>%
  collect_metrics() %>%
  filter(.metric == "mae") %>% 
  ggplot(aes(mtry, mean, color = .metric)) +
  geom_line(size = 1.5) +
  scale_x_log10() +
  theme(legend.position = "none") +
  labs(title = "MAE")
```

```{r}
tune_result %>% show_best(metric = "mae") %>% kable()
```

```{r}
tune_best <- tune_result %>% select_best(metric = "mae")
tune_best$mtry
tune_best$min_n
```

# Elastic Net regeression ëª¨ë¸ ì„¤ì • ë° í•™ìŠµ

`mixture`ì™€ `penalty` ëª¨ìˆ˜ë¥¼ íŠœë‹ ëœ ìµœì  ëª¨ìˆ˜ë¡œ í•™ìŠµì‹œí‚¨ë‹¤.

```{r trainrf, message=FALSE, warning=FALSE}
cores <- parallel::detectCores() -1
cores

rf_model <- 
  rand_forest(mtry = tune_best$mtry,
              min_n = tune_best$min_n,
              trees = 1000) %>% 
    set_engine("ranger", seed = 2021, num.threads = cores) %>% 
    set_mode("regression")

tic()
rf_fit <- 
    rf_model %>% 
    fit(weekly_sales ~ ., data = train2)
toc()

options(max.print = 10)
rf_fit
```

# Prediction and submit (ì˜ˆì¸¡ ë° í‰ê°€)

```{r warning=FALSE}
result <- predict(rf_fit, test2)
result %>% head()
result
```

```{r}
submission <- read_csv(file.path(file_path, "sampleSubmission.csv.zip"))
submission$Weekly_Sales <- result$.pred
write.csv(submission, row.names = FALSE,
          "random_forest_tuned.csv")
submission %>% head()
```


