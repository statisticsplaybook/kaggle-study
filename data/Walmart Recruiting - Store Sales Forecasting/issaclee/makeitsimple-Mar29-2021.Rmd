---
title: "Make it simple."
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 5
    fig_height: 4
    theme: cosmo
    highlight: tango
    code_folding: show
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = "center")
```


![Photo steal from [here](https://connectedremag.com/das-in-building-wireless/walmart-verizon-explore-testing-5g-in-some-stores/)](https://connectedremag.com/wp-content/uploads/2020/03/walmart-5G-connected-real-estate.png)

This posting is the part of my youtube channel study about [Kaggling with R](https://www.youtube.com/playlist?list=PLKtLBdGREmMlJCXjCpCi5B4KQ-TsFvAAi).

# Back to the basic.

I was playing around this old competion for a while. I have tried to use regression based model (Elastic net) and tree model (Random forest) using tidymodel. If you see the dataset, this is basically year, month, store, and department based sales price. Therefore, the tree based model performs better in this dataset by its nature. However, I was surprised to see that the comment from [David Thaler](https://www.kaggle.com/davidthaler), who took thefirst place of this competition and now he is the Grandmaster, saying that the group mean by month, store, dept, and is_holyday can beat regression and random forest easily. This notebook will show that the simple group mean can beat most of the competitors. 

# ì¤€ë¹„ì‘ì—… {.tabset .tabset-fade}

## Library load

ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œ ì‚¬ìš©í•  RíŒ¨í‚¤ì§€ë“¤ì„ ë¶ˆëŸ¬ì˜¤ì. íŠ¹íˆ ìš”ì¦˜ í•«í•˜ë”” í•«í•œ `tidymodels` ì‚¬ìš©í•˜ì—¬ ì›”ë§ˆíŠ¸ ëŒ€íšŒë¥¼ ê°€ì§€ê³  ë†€ì•„ë³¸ë‹¤. ë˜í•œ ë§ˆì´ ë¹¼ì´ë³´ë¦¿ ì—°ì‚°ìë“¤ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•˜ì—¬ `magrittr`ë¥¼ ë¶ˆëŸ¬ì™”ë‹¤.ğŸ¤£

```{r load_lib, message=FALSE, warning=FALSE, results='hide'}
library(tidymodels)
library(tidyverse)
library(magrittr)
library(skimr)
library(knitr)
theme_set(theme_bw())
```

## Dataset load

ì´ ëŒ€íšŒì—ì„œ ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ë³´ì. ì£¼ì–´ì§„ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

```{r}
file_path <- "../input/walmart-recruiting-store-sales-forecasting/"
files <- list.files(file_path)
files
```
ê° ë³€ìˆ˜ì˜ ì´ë¦„ì„ `janitor` íŒ¨í‚¤ì§€ë¡œ ë§ë”í•˜ê²Œ ë°”ê¿”ì¤€ë‹¤.

```{r, message=FALSE}
train <- read_csv(file.path(file_path, "train.csv.zip")) %>% 
  janitor::clean_names()
test <- read_csv(file.path(file_path, "test.csv.zip")) %>% 
  janitor::clean_names()
features <- read_csv(file.path(file_path, "features.csv.zip")) %>% 
  janitor::clean_names()
stores <- read_csv(file.path(file_path, "stores.csv")) %>% 
  janitor::clean_names()
```

# ë°ì´í„° ê¸°ë³¸ì •ë³´ í™•ì¸{.tabset .tabset-fade}

## Basic info.

ì´ ëŒ€íšŒëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê°„ë‹¨í•œ ëŒ€íšŒì´ë‹¤. ì²«ë²ˆì§¸ ìŠ¤í„°ë””ìš© ëŒ€íšŒë¡œ ì„ íƒì„ í•œ ì´ìœ ì´ê¸°ë„ í•˜ë‹¤. ì£¼ ë°ì´í„°ëŠ” 42ë§Œê°œì˜ train ìƒ˜í”Œê³¼ 11ë§Œê°œì˜ test ìƒ˜í”Œë¡œ êµ¬ì„±ì´ ë˜ì–´ìˆë‹¤.

```{r}
dim(train)
dim(test)
```

ë³€ìˆ˜ëª…ì„ ì‚´í´ë³´ë©´, ì›”ë§ˆíŠ¸ ê°€ë§¹ì ì„ ëœ»í•˜ëŠ” `store` ë³€ìˆ˜ì™€ ë§¤ì¥ì•ˆì˜ ë¶€ì„œë“¤ì„ ë‚˜íƒ€ë‚´ëŠ” `dept`, ë‚ ì§œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆëŠ” `date`ì™€ `is_holiday`, ë§ˆì§€ë§‰ìœ¼ë¡œ ìš°ë¦¬ì˜ target ë³€ìˆ˜ì¸ `weekly_sales`ê°€ ìˆëŠ” ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.

```{r}
names(train)
names(test)
```

## train and test data snippet

```{r}
head(train) %>% kable()
head(train) %>% kable()
```

## store data

`store` ë°ì´í„°ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ê°„ë‹¨í•˜ë‹¤. ê° ì í¬ì— ëŒ€í•œ ì‚¬ì´ì¦ˆì™€ íƒ€ì…ë³€ìˆ˜ê°€ ë‹´ê²¨ì ¸ ìˆë‹¤. íƒ€ì…ë³€ìˆ˜ëŠ” ì›”ë§ˆíŠ¸ì—ì„œ ìš´ì˜í•˜ëŠ” supercenterì™€ ê°™ì´ ë§¤ì¥ì˜ ì„±ê²©ì„ ë‚˜íƒ€ë‚´ëŠ” ë³€ìˆ˜ì´ë‹¤.

```{r}
dim(stores)
head(stores) %>% kable()
```


## feature data

`feature` ë°ì´í„°ëŠ” ì¡°ê¸ˆ ë³µì¡í•œë°, ê° ì í¬ë³„ë¡œ ê° ì£¼ë§ˆë‹¤ì˜ ì •ë³´ê°€ ë‹´ê²¨ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

```{r}
dim(features)
length(unique(features$store)) * length(unique(features$date))

head(features) %>% kable()
```

ì¼ë‹¨ `NA`ì˜ ì¡´ì¬ê°€ ë§ìŒ. `skim()` í•¨ìˆ˜ì˜ complete ì •ë³´ë¥¼ í†µí•˜ì—¬ ì•Œì•„ ë³¼ ìˆ˜ ìˆë‹¤. ë˜í•œ, ëŒ€íšŒ ë°ì´í„°ì— ëŒ€í•œ ì„¤ëª…ì„ ë³´ë©´ `mark_down1-5` ë³€ìˆ˜ì˜ ê²½ìš° ì›”ë§ˆíŠ¸ì—ì„œ ì§„í–‰í•˜ê³  ìˆëŠ” Promotionì„ ì˜ë¯¸í•œë‹¤. í•˜ì§€ë§Œ ì´ ë³€ìˆ˜ì˜ ê²½ìš° 2011ë…„ 11ì›” ì´í›„ì— ë‚ ì§œì— ëŒ€í•˜ì—¬ë§Œ ì ‘ê·¼ ê°€ëŠ¥í•˜ê³ , ê·¸ ì´ì „ì˜ ê²½ìš°ì—ëŠ” `NA`ë¡œ ì±„ì›Œì ¸ìˆë‹¤. ì´ëŸ¬í•œ `NA`ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•  ê²ƒì¸ê°€ê°€ ì´ ëŒ€íšŒì˜ í•µì‹¬ì¼ ê²ƒ ê°™ë‹¤.

# íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” {.tabset .tabset-fade}

## `weekly_sales`

ë¨¼ì € ìš°ë¦¬ì˜ ì˜ˆì¸¡ ëª©í‘œì¸ ì£¼ê°„ ì„¸ì¼ë³€ìˆ˜ `weekly_sales`ë¥¼ ì‹œê°í™” í•´ë³´ë„ë¡ í•˜ì.

```{r message=FALSE, class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = weekly_sales)) +
  geom_histogram()
```

ë§¤ì¶œì•¡ì˜ ë¶„í¬ë¼ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì—„ì²­ ì¹˜ìš°ì³ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ëŸ° ê²½ìš° ë³´í†µ `log` í•¨ìˆ˜ë¥¼ ì·¨í•´ì¤˜ì„œ ë¶„í¬ì˜ ì¹˜ìš°ì¹¨ì„ ì¡ì•„ì¤€ë‹¤. ì´ë ‡ê²Œ ë¶„í¬ ì¹˜ìš°ì¹¨ì„ ì¡ì•„ì£¼ëŠ” ì´ìœ ëŠ” íšŒê·€ë¶„ì„ ê°™ì€ ì „í†µì ì¸ ê¸°ë²•ì˜ ê²½ìš° ë°ì´í„°ì— ì„ì—¬ìˆëŠ” ì¡ìŒì˜ ë¶„í¬ë¥¼ ì •ê·œë¶„í¬ê°™ì´ ëŒ€ì¹­ì¸ ë¶„í¬ë¡œ ê°€ì •í•˜ëŠ” ê²½ìš°ê°€ ë§ê¸° ë•Œë¬¸ì´ë‹¤. 

```{r message=FALSE, class.source = 'fold-hide'}
train %>% 
    ggplot(aes(x = sign(weekly_sales) * log(abs(weekly_sales) + 2))) +
    geom_histogram() +
    labs(title = "Transformed distribution of weekly sales 1",
         x = "weekly_sales")
```

`log`ë¥¼ ì·¨í•´ì£¼ì—ˆì„ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì´ ì¹˜ìš°ì¹¨ì´ ë§ì´ ì¡íˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ìœ„ì˜ ë¶„í¬ ì—­ì‹œ ì™¼ìª½ìœ¼ë¡œ ì¹˜ìš°ì³ ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë¶„í¬ë¥¼ ì¡°ê¸ˆ ë” ì¢…ëª¨ì–‘ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ê¸° ìœ„í•˜ì—¬ ì œê³±ê·¼ì„ ì´ìš©í–ˆë‹¤. ì•„ë˜ë¥¼ ë³´ë©´ ë¶„í¬ê°€ ì¢…ëª¨ì–‘ì²˜ëŸ¼ ì˜ˆë»ì§„ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

```{r message=FALSE, class.source = 'fold-hide'}
train %>% 
    ggplot(aes(x = sign(weekly_sales) * (abs(weekly_sales))^(1/5))) +
    geom_histogram() +
    labs(title = "Transformed distribution of weekly sales 2",
         x = "weekly_sales")
```

# ì „ì²˜ë¦¬ ë ˆì‹œí”¼(`recipe`) ë§Œë“¤ê¸°

tidymodelsì˜ ì „ì²˜ë¦¬ íŒ¨í‚¤ì§€ì§€ recipeì„ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬ë¥¼ í•˜ë„ë¡í•˜ì.

## `all_data` í•©ì¹˜ê¸°

ë¨¼ì € `store` ì™€ `features` ë°ì´í„°ì— ìˆëŠ” ì •ë³´ë¥¼ `train`ê³¼ `test` ë°ì´í„°ì— ì˜®ê²¨ì˜¤ì. ì¼ë‹¨ ê²°ì¸¡ì¹˜ê°€ ì—†ëŠ” ë³€ìˆ˜ë“¤ë§Œ ê°€ì ¸ì˜¤ê³ , ì¶”í›„ì— ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ë³€ìˆ˜ì¸ cpiì™€ unemployment, mark_down ë³€ìˆ˜ë“¤ì„ ê°€ì ¸ì˜¤ì.

```{r}
train$weekly_sales <- sign(train$weekly_sales) * (abs(train$weekly_sales))^(1/5)
all_data <- bind_rows(train, test)
all_data %>% head()
names(all_data)
dim(all_data)
```

## ì „ì²˜ë¦¬ ê³¼ì • ê¸°ë¡í•˜ê¸°

tidymodelì˜ í¸ë¦¬í•œ ì¥ì  ì¤‘ í•˜ë‚˜ëŠ” ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì œê³µí•´ì„œ ì‹¤ì œë¡œ ì „ì²˜ë¦¬ ì½”ë”©ì„ í•˜ì§€ ì•Šì•„ë„ ë˜ë„ë¡ ìë™í™” ì‹œì¼œë†“ì€ ê²ƒì´ë‹¤. ì „ì²˜ë¦¬ë¥¼ í•˜ê³ ì í•˜ëŠ” ë°©ë²•ì„ recipeì— ì ì–´ì£¼ë©´, ë‚˜ì¤‘ì— í•œë²ˆì— ì „ì²˜ë¦¬ë¥¼ ì‹œì¼œì¤€ë‹¤.

ë‹¤ìŒì˜ recipeì—ëŠ” `date` ë³€ìˆ˜ì—ì„œ ë‚ ì§œ ì •ë³´ë¥¼ ë¹¼ì˜¤ê³ , `temperature, fuel_price, cpi, unemployment` ë³€ìˆ˜ë“¤ì„ 10ì°¨í•­ê¹Œì§€ ì½”ë”©í•´ì„œ ë„£ì–´ì£¼ëŠ” ì „ì²˜ë¦¬ ê³¼ì •ì´ ë“¤ì–´ìˆë‹¤.

```{r}
walmart_recipe <- all_data %>% 
    recipe(weekly_sales ~ .) %>%
    step_mutate(month = lubridate::month(date)) %>% 
    step_rm(date) %>% 
    prep(training = all_data)

print(walmart_recipe)
```

## ì „ì²˜ë¦¬ ë°ì´í„° ì§œë‚´ê¸° (`juice`)

ì €ì¥ëœ `recipe`ì˜ ì „ì²˜ë¦¬ë¥¼ í•œ ë°ì´í„°ë¥¼ `juice` í•¨ìˆ˜ë¡œ ì§œë‚´ë³´ì.

```{r}
all_data2 <- juice(walmart_recipe)
all_data2 %>% dim()
all_data2 %>% head() %>% 
  kable()
```

# ëª¨ë¸ í•™ìŠµí•˜ê¸°

## ë°ì´í„° ë‚˜ëˆ„ê¸°

```{r}
train_index <- seq_len(nrow(train))
train2 <- all_data2[train_index,]
test2 <- all_data2[-train_index,]
```

## ì í¬-ë¶€ì„œ-ì›”ë³„ í‰ê· 

```{r}
mean_model <- train2 %>% 
  group_by(store, dept, month, is_holiday) %>% 
  summarise(weekly_sales = mean(weekly_sales, rm.na = TRUE))

median_model <- train2 %>% 
  group_by(store, dept, month, is_holiday) %>% 
  summarise(weekly_sales = median(weekly_sales, rm.na = TRUE))

result <- test2 %>% 
  select(-weekly_sales) %>% 
  left_join(y = median_model, 
            by = c("store"="store",
                   "dept" ="dept",
                   "month"="month",
                   "is_holiday"="is_holiday")) %>% 
  select(weekly_sales) %>% 
  mutate(weekly_sales = sign(weekly_sales) * (abs(weekly_sales)^5)) %>% 
  unlist() %>% as.numeric()

# Manage NA's
result %>% head()
is.na(result) %>% sum()
result[is.na(result)] <- 0
```

# ì œì¶œí•˜ê¸°

```{r}
submission <- read_csv(file.path(file_path, "sampleSubmission.csv.zip"))
submission$Weekly_Sales <- result
write.csv(submission, row.names = FALSE,
          "mean_model.csv")
submission %>% head()
```


